{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":88742,"databundleVersionId":10173359,"sourceType":"competition"},{"sourceId":494959,"sourceType":"modelInstanceVersion","modelInstanceId":393014,"modelId":411634},{"sourceId":494960,"sourceType":"modelInstanceVersion","modelInstanceId":393015,"modelId":411635},{"sourceId":494963,"sourceType":"modelInstanceVersion","modelInstanceId":393017,"modelId":411637},{"sourceId":495224,"sourceType":"modelInstanceVersion","modelInstanceId":393175,"modelId":411779}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Competition overview","metadata":{}},{"cell_type":"markdown","source":"**Competition Summary**\n\n- This is the Rohlik Sales Forecasting Challenge, a time-series forecasting competition hosted on Kaggle. The primary objective is to predict the sales volume for various inventory items across 11 different Rohlik Group warehouses for a period of 14 days.\n\n- Accurate forecasts are vital for the e-grocery company's operations, as they directly impact supply chain efficiency, inventory management, and overall sustainability by minimizing waste.\n\n- The model's performance will be evaluated using the Weighted Mean Absolute Error (WMAE). The specific weights for each inventory item are provided in a separate file. The competition runs from November 15, 2024, to February 15, 2025, and offers cash prizes for the top three competitors.\n\n- The dataset includes historical sales and order data, product metadata, and a calendar with holiday information. Some features available in the training set (e.g., sales and availability) are intentionally removed from the test set, as they would not be known at the time of a real-world prediction.","metadata":{}},{"cell_type":"markdown","source":"# Data Dictionary","metadata":{}},{"cell_type":"markdown","source":"This data dictionary describes the files and columns provided for the competition.","metadata":{}},{"cell_type":"markdown","source":"**sales_train.csv and sales_test.csv**","metadata":{}},{"cell_type":"markdown","source":"<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-za14{border-color:inherit;text-align:left;vertical-align:bottom}\n.tg .tg-7zrl{text-align:left;vertical-align:bottom}\n</style>\n<table class=\"tg\"><thead>\n  <tr>\n    <th class=\"tg-za14\">Column</th>\n    <th class=\"tg-7zrl\">Description</th>\n    <th class=\"tg-7zrl\">Data Type</th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td class=\"tg-7zrl\">unique_id</td>\n    <td class=\"tg-7zrl\">A unique identifier for a specific inventory item in a specific warehouse.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">date</td>\n    <td class=\"tg-7zrl\">The date of the sales record.</td>\n    <td class=\"tg-7zrl\">Date</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">warehouse</td>\n    <td class=\"tg-7zrl\">The name of the warehouse where the item is stored.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">total_orders</td>\n    <td class=\"tg-7zrl\">The historical number of orders for the selected warehouse.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">sales</td>\n    <td class=\"tg-7zrl\">The target variable: sales volume (pcs or kg).</td>\n    <td class=\"tg-7zrl\">Float</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">sell_price_main</td>\n    <td class=\"tg-7zrl\">The selling price of the item.</td>\n    <td class=\"tg-7zrl\">Float</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">availability</td>\n    <td class=\"tg-7zrl\">The proportion of the day the item was available. A value of 1 means it was available all day.</td>\n    <td class=\"tg-7zrl\">Float</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">type_0_discount, type_1_discount, etc.</td>\n    <td class=\"tg-7zrl\">The percentage discount offered for various promotion types. Negative values indicate no discount.</td>\n    <td class=\"tg-7zrl\">Float</td>\n  </tr>\n</tbody></table>","metadata":{}},{"cell_type":"markdown","source":"**inventory.csv**","metadata":{}},{"cell_type":"markdown","source":"<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-za14{border-color:inherit;text-align:left;vertical-align:bottom}\n.tg .tg-7zrl{text-align:left;vertical-align:bottom}\n</style>\n<table class=\"tg\"><thead>\n  <tr>\n    <th class=\"tg-za14\">Column</th>\n    <th class=\"tg-7zrl\">Description</th>\n    <th class=\"tg-7zrl\">Data Type</th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td class=\"tg-7zrl\">unique_id</td>\n    <td class=\"tg-7zrl\">A unique identifier for a specific inventory item.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">product_unique_id</td>\n    <td class=\"tg-7zrl\">A unique identifier for a product, shared across all warehouses.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">name</td>\n    <td class=\"tg-7zrl\">The name of the product.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">L1_category_name, L2_category_name, etc.</td>\n    <td class=\"tg-7zrl\">Hierarchical category names for the product. L4 is the most granular.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">warehouse</td>\n    <td class=\"tg-7zrl\">The name of the warehouse where the inventory item is located.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n</tbody></table>","metadata":{}},{"cell_type":"markdown","source":"**calendar.csv**","metadata":{}},{"cell_type":"markdown","source":"<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-za14{border-color:inherit;text-align:left;vertical-align:bottom}\n.tg .tg-7zrl{text-align:left;vertical-align:bottom}\n</style>\n<table class=\"tg\"><thead>\n  <tr>\n    <th class=\"tg-za14\">Column</th>\n    <th class=\"tg-7zrl\">Description</th>\n    <th class=\"tg-7zrl\">Data Type</th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td class=\"tg-7zrl\">warehouse</td>\n    <td class=\"tg-7zrl\">The name of the warehouse.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">date</td>\n    <td class=\"tg-7zrl\">The date of the calendar event.</td>\n    <td class=\"tg-7zrl\">Date</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">holiday_name</td>\n    <td class=\"tg-7zrl\">The name of the public holiday, if applicable.</td>\n    <td class=\"tg-7zrl\">String</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">holiday</td>\n    <td class=\"tg-7zrl\">A binary flag (0 or 1) indicating if the date is a holiday.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">shops_closed</td>\n    <td class=\"tg-7zrl\">A flag indicating a public holiday where most shops are closed.</td>\n    <td class=\"tg-7zrl\">Boolean</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">winter_school_holidays</td>\n    <td class=\"tg-7zrl\">A flag for winter school holidays.</td>\n    <td class=\"tg-7zrl\">Boolean</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">school_holidays</td>\n    <td class=\"tg-7zrl\">A flag for general school holidays.</td>\n    <td class=\"tg-7zrl\">Boolean</td>\n  </tr>\n</tbody></table>","metadata":{}},{"cell_type":"markdown","source":"**test_weights.csv**","metadata":{}},{"cell_type":"markdown","source":"<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-za14{border-color:inherit;text-align:left;vertical-align:bottom}\n.tg .tg-7zrl{text-align:left;vertical-align:bottom}\n</style>\n<table class=\"tg\"><thead>\n  <tr>\n    <th class=\"tg-za14\">Column</th>\n    <th class=\"tg-7zrl\">Description</th>\n    <th class=\"tg-7zrl\">Data Type</th>\n  </tr></thead>\n<tbody>\n  <tr>\n    <td class=\"tg-7zrl\">unique_id</td>\n    <td class=\"tg-7zrl\">A unique identifier for the inventory item.</td>\n    <td class=\"tg-7zrl\">Integer</td>\n  </tr>\n  <tr>\n    <td class=\"tg-7zrl\">weight</td>\n    <td class=\"tg-7zrl\">The weight used for calculating the Weighted Mean Absolute Error (WMAE) metric for this item.</td>\n    <td class=\"tg-7zrl\">Float</td>\n  </tr>\n</tbody>\n</table>","metadata":{}},{"cell_type":"markdown","source":"## [Link to competition](https://www.kaggle.com/competitions/rohlik-sales-forecasting-challenge-v2/overview)","metadata":{}},{"cell_type":"markdown","source":"# Model training notebook","metadata":{}},{"cell_type":"markdown","source":"## [Model training notebook](https://www.kaggle.com/code/misterfour/rohik-sales-forecasting-challenge)","metadata":{}},{"cell_type":"markdown","source":"## [Reference! (add holidays calendar of each country into dataset)](https://www.kaggle.com/competitions/rohlik-sales-forecasting-challenge-v2/overview)","metadata":{}},{"cell_type":"markdown","source":"# Import necessary libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:07:51.009822Z","iopub.execute_input":"2025-07-29T11:07:51.010110Z","iopub.status.idle":"2025-07-29T11:07:53.472232Z","shell.execute_reply.started":"2025-07-29T11:07:51.010069Z","shell.execute_reply":"2025-07-29T11:07:53.471248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install TensorFlow and Keras\n!pip install tensorflow==2.15.0\n!pip install keras==2.15.0\n!pip install scikit-learn==1.2.2\nfrom joblib import Parallel, delayed\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\nimport joblib\nfrom tensorflow.keras.layers import Input, Conv1D, Multiply, Add, Dense, Dropout, LayerNormalization\nfrom tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D, Activation, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Metric\nfrom sklearn.preprocessing import OrdinalEncoder\nimport joblib\nimport pandas as pd\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.preprocessing import StandardScaler\nfrom joblib import Parallel, delayed\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nimport joblib\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, Add, Activation, Dense, Dropout,\n    BatchNormalization, GlobalAveragePooling1D, Multiply, LayerNormalization\n)\nfrom tensorflow.keras.layers import MultiHeadAttention","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:28:29.389440Z","iopub.execute_input":"2025-07-29T23:28:29.389724Z","iopub.status.idle":"2025-07-29T23:29:43.873713Z","shell.execute_reply.started":"2025-07-29T23:28:29.389702Z","shell.execute_reply":"2025-07-29T23:29:43.872463Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load dataset and preprocess dataset","metadata":{}},{"cell_type":"code","source":"# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Hyperparameters (must match training pipeline)\nSEQUENCE_LENGTH = 100\nBATCH_SIZE = 256\n\n# Additional holiday days (unchanged)\nczech_holiday = [\n    (['03/31/2024', '04/09/2023', '04/17/2022', '04/04/2021', '04/12/2020'], 'Easter Day'),\n    (['05/12/2024', '05/10/2020', '05/09/2021', '05/08/2022', '05/14/2023'], \"Mother Day\"),\n]\nbrno_holiday = [\n    (['03/31/2024', '04/09/2023', '04/17/2022', '04/04/2021', '04/12/2020'], 'Easter Day'),\n    (['05/12/2024', '05/10/2020', '05/09/2021', '05/08/2022', '05/14/2023'], \"Mother Day\"),\n]\nmunich_holidays = [\n    (['03/30/2024', '04/08/2023', '04/16/2022', '04/03/2021'], 'Holy Saturday'),\n    (['05/12/2024', '05/14/2023', '05/08/2022', '05/09/2021'], 'Mother Day'),\n]\nfrankfurt_holidays = [\n    (['03/30/2024', '04/08/2023', '04/16/2022', '04/03/2021'], 'Holy Saturday'),\n    (['05/12/2024', '05/14/2023', '05/08/2022', '05/09/2021'], 'Mother Day'),\n]\n\n# Functions (unchanged)\ndef fill_loss_holidays(df_fill, warehouses, holidays):\n    df = df_fill.copy()\n    for item in holidays:\n        dates, holiday_name = item\n        generated_dates = [pd.to_datetime(date, format='%m/%d/%Y').strftime('%Y-%m-%d') for date in dates]\n        for generated_date in generated_dates:\n            df.loc[(df['warehouse'].isin(warehouses)) & (df['date'] == generated_date), 'holiday'] = 1\n            df.loc[(df['warehouse'].isin(warehouses)) & (df['date'] == generated_date), 'holiday_name'] = holiday_name\n    return df\n\ndef enrich_calendar(df):\n    df = df.sort_values('date').reset_index(drop=True)\n    df['next_holiday_date'] = df.loc[df['holiday'] == 1, 'date'].shift(-1)\n    df['next_holiday_date'] = df['next_holiday_date'].bfill()\n    df['date_days_to_next_holiday'] = (df['next_holiday_date'] - df['date']).dt.days\n    df.drop(columns=['next_holiday_date'], inplace=True)\n    df['next_shops_closed_date'] = df.loc[df['shops_closed'] == 1, 'date'].shift(-1)\n    df['next_shops_closed_date'] = df['next_shops_closed_date'].bfill()\n    df['date_days_to_shops_closed'] = (df['next_shops_closed_date'] - df['date']).dt.days\n    df.drop(columns=['next_shops_closed_date'], inplace=True)\n    df['date_day_after_closed_day'] = ((df['shops_closed'] == 0) & (df['shops_closed'].shift(1) == 1)).astype(int)\n    df['date_second_closed_day'] = ((df['shops_closed'] == 1) & (df['shops_closed'].shift(1) == 1)).astype(int)\n    df['date_day_after_two_closed_days'] = ((df['shops_closed'] == 0) & (df['date_second_closed_day'].shift(1) == 1)).astype(int)\n    return df\n\ndef stack_datasets(df, calendar_extended, inventory, weights):\n    df = df.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n    df = df.merge(inventory, on=['unique_id', 'warehouse'], how='left')\n    df = df.merge(weights, on='unique_id', how='left')\n    df['date'] = pd.to_datetime(df['date'])\n    return df\n\ndef sort_dataframe_by_date(df, date_column):\n    df[date_column] = pd.to_datetime(df[date_column])\n    df = df.sort_values(by=date_column)\n    return df\n\ndef encode_datetime(df, datetime_column):\n    df[datetime_column] = pd.to_datetime(df[datetime_column])\n    df['year'] = df[datetime_column].dt.year\n    df['month'] = df[datetime_column].dt.month\n    df['day'] = df[datetime_column].dt.day\n    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n    df['sin_day'] = np.sin(2 * np.pi * df['day'] / 31)\n    df['cos_day'] = np.cos(2 * np.pi * df['day'] / 31)\n    df.drop(datetime_column, axis=1, inplace=True)\n    return df\n\n# Load datasets\ntrain = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv', parse_dates=['date'])\ninventory = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/inventory.csv')\nsubmission = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv', parse_dates=['date'])\nweights = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/test_weights.csv')\n\n# Load and preprocess calendar\ncalendar = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/calendar.csv', parse_dates=['date'])\ncalendar = fill_loss_holidays(calendar, ['Prague_1', 'Prague_2', 'Prague_3'], czech_holiday)\ncalendar = fill_loss_holidays(calendar, ['Brno_1'], brno_holiday)\ncalendar = fill_loss_holidays(calendar, ['Munich_1'], munich_holidays)\ncalendar = fill_loss_holidays(calendar, ['Frankfurt_1'], frankfurt_holidays)\n\ncalendar_enriched = pd.DataFrame()\nfor location in ['Frankfurt_1', 'Prague_2', 'Brno_1', 'Munich_1', 'Prague_3', 'Prague_1', 'Budapest_1']:\n    calendar_enriched = pd.concat([calendar_enriched, enrich_calendar(calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse == @location'))])\ncalendar_enriched['year'] = calendar_enriched['date'].dt.year\ncalendar_enriched = calendar_enriched.rename(columns={\n    'holiday_name': 'date_holiday_name',\n    'year': 'date_year',\n    'holiday': 'date_holiday_flag',\n    'shops_closed': 'date_shops_closed_flag',\n    'winter_school_holidays': 'date_winter_school_holidays_flag',\n    'school_holidays': 'date_school_holidays_flag',\n})\n\n# Stack datasets\ndf_submission = stack_datasets(submission, calendar_enriched, inventory, weights)\ndf_submission['date_holiday_name'] = df_submission['date_holiday_name'].fillna('Working Day')\n\n# Fill NaN values\nfor col in df_submission.select_dtypes(include=np.number).columns:\n    if df_submission[col].isnull().any():\n        mean_val = df_submission[col].mean()\n        df_submission[col] = df_submission[col].fillna(mean_val)\n        print(f\"Filled NaN in df_submission['{col}'] with mean: {mean_val:.2f}\")\n\n# Sort by date\ndf_submission = sort_dataframe_by_date(df_submission, 'date')\nsubmission = df_submission.copy()\n# Drop noise columns\ncolumns_to_drop = [\n    'type_2_discount',\n    'date_holiday_flag',\n    'date_school_holidays_flag',\n    'date_shops_closed_flag',\n    'date_second_closed_day',\n    'date_winter_school_holidays_flag',\n    'date_day_after_closed_day',\n    'date_day_after_two_closed_days',\n    'type_5_discount',\n    'type_3_discount',\n    'type_1_discount',\n    'unique_id',\n    \"availability\"\n]\ndf_submission = df_submission.drop(columns=columns_to_drop, axis=1, errors='ignore')\n\n# Preprocess data\ndef preprocess_data(df, encoder_path='/kaggle/input/rohik_encoder_v2/scikitlearn/default/1/encoder.pkl', scaler_path='/kaggle/input/rohik_scaler_v2/scikitlearn/default/1/scaler.pkl'):\n    weight = df['weight'].values.astype(np.float32)\n    x = df.drop(['weight'], axis=1).copy()\n\n    datetime_cols = x.select_dtypes(include=['datetime']).columns\n    if len(datetime_cols) > 0:\n        for col in datetime_cols:\n            x[col + '_month'] = x[col].dt.month\n            x[col + '_day'] = x[col].dt.day\n        x = x.drop(datetime_cols, axis=1)\n\n    categorical_cols = x.select_dtypes(include=['object', 'category']).columns\n    numeric_cols = x.select_dtypes(include=['number']).columns\n\n    encoder = joblib.load(encoder_path)\n    scaler = joblib.load(scaler_path)\n    if len(categorical_cols) > 0:\n        x[categorical_cols] = encoder.transform(x[categorical_cols])\n    if len(numeric_cols) > 0:\n        x[numeric_cols] = scaler.transform(x[numeric_cols])\n\n    x = x.values.astype(np.float32)\n    return x, weight\n\nx_submission, weight_submission = preprocess_data(df_submission)\n\n# Pad x_submission for sequence length\npad_length = SEQUENCE_LENGTH - 1\nx_submission_padded = np.pad(x_submission, ((pad_length, 0), (0, 0)), mode='constant', constant_values=0)\n\n# Function to create test dataset\ndef create_test_dataset(features, weights, sequence_length, batch_size):\n    dataset = tf.keras.utils.timeseries_dataset_from_array(\n        data=features,\n        targets=None,\n        sequence_length=sequence_length,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    aligned_weights = weights[-len(features):]\n    return dataset, aligned_weights\n\n# Create test dataset\ndataset_submission, aligned_weights = create_test_dataset(x_submission_padded, weight_submission, SEQUENCE_LENGTH, BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T00:18:47.532584Z","iopub.execute_input":"2025-07-30T00:18:47.532830Z","iopub.status.idle":"2025-07-30T00:26:11.074464Z","shell.execute_reply.started":"2025-07-30T00:18:47.532800Z","shell.execute_reply":"2025-07-30T00:26:11.073614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"# Custom WMAE Loss Function\ndef custom_wmae_loss(y_true, y_pred, sample_weight=None):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    if sample_weight is None:\n        sample_weight = tf.ones_like(y_true, dtype=tf.float32)\n    else:\n        sample_weight = tf.cast(sample_weight, tf.float32)\n    weighted_error = tf.abs(y_true - y_pred) * sample_weight\n    sum_of_weights = tf.reduce_sum(sample_weight)\n    return tf.cond(\n        tf.greater(sum_of_weights, 0),\n        lambda: tf.reduce_sum(weighted_error) / sum_of_weights,\n        lambda: tf.constant(0.0, dtype=tf.float32)\n    )\n\n# Custom WMAE Metric\nclass WeightedMAEMetric(Metric):\n    def __init__(self, name='wmae', **kwargs):\n        super(WeightedMAEMetric, self).__init__(name=name, **kwargs)\n        self.total_weighted_error = self.add_weight(name='total_weighted_error', initializer='zeros')\n        self.total_weights = self.add_weight(name='total_weights', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        if sample_weight is None:\n            sample_weight = tf.ones_like(y_true, dtype=tf.float32)\n        else:\n            sample_weight = tf.cast(sample_weight, tf.float32)\n        weighted_error = tf.abs(y_true - y_pred) * sample_weight\n        self.total_weighted_error.assign_add(tf.reduce_sum(weighted_error))\n        self.total_weights.assign_add(tf.reduce_sum(sample_weight))\n\n    def result(self):\n        return tf.cond(\n            tf.greater(self.total_weights, 0),\n            lambda: self.total_weighted_error / self.total_weights,\n            lambda: tf.constant(0.0, dtype=tf.float32)\n        )\n\n    def reset_state(self):\n        self.total_weighted_error.assign(0.0)\n        self.total_weights.assign(0.0)\n\n# --- Save the model in Keras format (.keras) ---\n# Define the path for the .keras file\nkeras_model_path = \"/kaggle/input/wavenet_transformer_model.keras/keras/default/1/wavenet_transformer_model.keras\"\n\n# --- Load the model from Keras format (.keras) ---\nprint(f\"\\n--- Loading Model from '{keras_model_path}' ---\")\nmodel = tf.keras.models.load_model(\n    keras_model_path,\n    custom_objects={\n        'custom_wmae_loss': custom_wmae_loss,\n        'WeightedMAEMetric': WeightedMAEMetric\n    }\n)\nprint(\"Model loaded successfully!\")\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate predictions and create submission file","metadata":{}},{"cell_type":"code","source":"# Generate predictions\ny_pred_list = []\nfor x_batch in dataset_submission:\n    y_pred_batch = model.predict(x_batch, verbose=0)\n    y_pred_list.append(y_pred_batch)\n\ny_pred_padded = np.concatenate(y_pred_list, axis=0)\ny_pred = y_pred_padded[-len(x_submission):]\n\n# Load scaler for inverse transformationa\nscaler_y = joblib.load('/kaggle/input/rohik_scaler_y_v2/scikitlearn/default/1/scaler_y.pkl')\ny_pred_unscaled = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n\n# Prepare submission\nsubmission['date'] = pd.to_datetime(submission['date']).dt.strftime('%Y-%m-%d')\n# Restore unique_id since it was dropped\nsubmission['id'] = submission['unique_id'].astype(str) + '_' + submission['date']\nsubmission['sales_hat'] = y_pred_unscaled\nsubmission_final = submission[['id', 'sales_hat']]\n\n# Save submission\nsubmission_final.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved to submission.csv\")\nsubmission_final","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}